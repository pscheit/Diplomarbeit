\chapter{Zusammenfassung}

Die Probleme des \IM ergeben sich dadurch, dass sich die zwei Paradigma unabhängig voneinander entwickelten und somit andere Schwerpunkte bei der Modellierung der realen Welt setzten. Die Probleme erstrecken sich über die Struktur der Klassen, die Objektzustände, die Objektidentität und über das Prinzip der Kapselung bis zum Abfragen und Verarbeiten von Objekten. \\
Diese Probleme können entweder auf Softwareebene gelöst werden\footnote{z.~B. durch eine \ORM-Lösung} oder man ersetzt das relationale Datenbankmanagementsystem mit einem alternativen\footnote{zum Beispiel mit einem Objektdatenbankmanagementsystem}. Es wurde erklärt, warum sich \OODBMS nicht durchsetzen konnten und dass eine Kategorisierung der vorhandenen \DBMS als \ORDBMS schwer ist. Die relationalen \DBMS entwicklen sich in Richtung der \OODBMS weiter, die hauptsächlich Nischenmärkte versorgen. Da aber nicht für jedes der Kernprobleme bereits eine Lösung auf Datenbankebene existiert, muss ein \term{Object-relational Mapping} definiert werden. \\
Der Zustand eines Objektes wird dadurch gespeichert, dass seine Attribute in elementare oder erweiterte Datentypen zerlegt werden und als Datensätze in Tabellen der Datenbank gespeichert werden, die nach der Klasse des Objektes benannt sind. Dabei ist es möglich, dass ein Objekt auf mehrere Relationen verteilt wird. Besonders bei Klassenhierarchien ist die Struktur der Modellierung sorgfältig zu wählen, da sie unmittelbar Einfluss auf die Performanz oder Flexiblität der Anwendung haben kann. Beziehungen von Objekten werden so wie im relationalen Datenmodell gespeichert. Entweder fügt man Fremdschlüssel in Relationen ein oder verbindet alle Klassentabellen durch Zwischentabellen. \\
\\
Beim Laden und Hydrieren von Objekten, muss sich die \ORM-Lösung für eine odere mehrer Möglichkeiten entscheiden: Sie benutzt reines SQL und überlässt es dem Entwickler, alle möglicherweise verteilte Daten eines Objektes selbst auszuwählen und dem Objekt zur Verfügung zu stellen. Dabei muss der Entwickler der objektorientierten Applikation Kenntnisse über das Schema der Datenbank, über das Paradigma der relationalen Datenbanken und über den Datenbanktyp haben, um effizient arbeiten zu können. Man verliert in diesem Fall den Vorteil den Datenbanktyp ändern zu können oder gar das relationale Schema zu ändern, ohne den Quelltext der objektorientierten Applikation anzupassen. Die Applikation wird durch menschliche Fehler fehleranfälliger und unsicherer. Andererseits ist es dem Entwickler möglich die beste Performanz zu erreichen und es ist gewährleistet, dass er alle Optimierungen des relationalen Datenbanksystems nutzen kann. Die Abfragesprache (meistens ein SQL-Dialekt, welcher sehr gut bekannt ist) kann als Schnittstelle zur Datenbank uneingeschränkt genutzt werden, so dass dem Entwickler bekannte Methoden und Tools verwendet werden können. \\
Die zweite Möglichkeit ist, dass sich die \ORM-Lösung dazu entscheidet eine eigene API für den Massenzugriff auf Objekte bereitzustellen. Diese von mir genannte objektorientierte SQL API ist fehlerunfälliger und sicherer. Sie sollte aber den selben Funktionsumfang wie die Abfragesprache der Datenbank besitzen, was in der Praxis nicht immer gelingt\footnote{wie bei Kohana}. Die Abfragen werden in einer abstrakten Struktur modelliert, die unabhängig vom Datenbanktyp ist und in Abfragen der nativen Anfragesprache der Datenbank umgewandelt werden kann. Man gewinnt an Flexiblität, Effizienz und Sicherheit; Der Entwickler muss jedoch die objektorientierte SQL API so gut kennen, dass er seine Abfragen auch effizient formulieren kann und die Performanz der Abfragen nicht verschlechtert. \\
Die dritte und von Hibernate genutzte Möglichkeit ist, eine bekannte Abfragesprache\footnote{wie SQL} mit eigenen Sprachelementen abzuleiten und dem Entwickler zur Verfügung zu stellen. Der Benutzer der \ORM-Lösung kann nun auf gewohnte Art und Weise Abfragen an die Datenbank erstellen, ihm wird jedoch ermöglicht viele fehleranfällige Aufgaben, die er mit der nativen Anfragesprache selbst erledigen müsste, dem System zu übergeben. Die Abfragen werden dadurch kürzer, übersichtlicher, für menschliche Fehler unanfälliger und sicherer. Der Nachteil ist, dass die Abfrage zuerst geparst und ausgewertet werden muss, denn erst dann kann sie in eine native Abfrage an die Datenbank umgewandelt werden. Dies kostet zusätzliche Ressourcen und das System muss dafür Caching einsetzen. \\
Viele der großen \ORM-Lösungen bieten deshalb alle drei Möglichkeiten an, um dem Entwickler seine präferierte Methode selbst wählen zu lassen. Dabei wird davon ausgegangen, dass die Vor- und Nachteile verstanden und akzeptiert werden. \\
\\
Das Laden von Objekten wurde als spezielles Thema in dieser Arbeit behandelt. Die naive Lösung, in der jedes Objekt seine eigenen Anfragen schreibt und seine Attribute und \term{Mappings} selbst verwaltet, lässt sich mit einem \objectcache und der richtigen Abfragestrategie zu einer konkurrenzfähigen Lösung erweitern. Wird ein Objekt geladen, welches Unterobjekte agreggiert, lässt es seine Unterobjekte eigene Abfragen an die Datenbank stellen und somit seine Daten kapseln. \\
Die alternative Lösung ist, dass das Hauptobjekt die Daten für die Unterobjekte aus der Datenbank anfragt, und die Unterobjekte aus diesem Ergebnis ihre Daten erhalten. Beide Lösungen sind ungefähr gleich schnell, wenn beide einen \objectcache benutzen, der bereits instanziierte Objekte referenziert, so dass ein bereits geladenes Objekt nie wiederholt geladen werden muss. \\
Die richtige Strategie zum Laden der Objekte hat enorme Auswirkung auf die Performanz der Applikation. Dabei wird zwischen zwei Hauptstrategien unterschieden, die sich aber auch vermischen lassen: \term{Lazy Loading} und \term{Prefetching}. Beim \term{Lazy Loading} werden Unterobjekte eines Hauptobjektes nicht direkt geladen, wenn das Hauptobjekt aus der Datenbank geladen wird. In viele \ORM-Lösungen werden die Unterobjekte durch ein Proxy-Objekt ersetzt, welches erst dann zu einem richtigen Objekt transformiert wird, wenn die Applikation auf dieses Proxy-Objekt zugreift. Mit dieser Strategie werden nur die Daten aus der Datenbank geladen, die tatsächlich in der Applikation benötigt werden. Der Nachteil gegenüber der \term{Prefetching}-Strategie ist, dass zu viele Unterabfragen an die Datenbank gestellt werden, wenn die Anzahl der geforderten Objekte sehr groß wird. Es werden zuviele \term{Roundtrips} an die Datenbank benötigt, die die Laufzeit dominieren und die Performanz verschlechtern. Überschreitet das Verhältnis zwischen der Anzahl der angeforderten Objekte in der Applikation und der Anzahl der Objekte in der Datenbank insgesamt eine bestimmte Schwelle, ist \term{Prefetching} dem \term{Lazy Loading} vorzuziehen. Desto größer die Datensätze in der Datenbank für ein einzelnes Objekt sind, desto lukrativer ist es \term{Lazy Loading} zu benutzen. Desto kleiner die Datensätze, desto performanter ist es \term{Prefetching} zu benutzen. \\
\term{Prefetching} und \term{Lazy Loading} können auch auf weitere Bereiche beim Laden von Objekten ausgeweitet werden. So ist es z.~B. möglich einzelne Attribute von Objekten erst dann zu laden, wenn sie benötigt werden. Man könnte sich eine Übersicht von Artikeln vorstellen, die alle einen vierseitigen Text als BLOB in der Datenbank gespeichert haben. Würde eine Liste dieser Artikel-Objekte angezeigt, in denen nur der Titel und der Autor angezeigt werden, wäre das Laden des großen BLOB sicherlich fatal für die Performanz. Man könnte dann den Text des Artikel-Objektes erst laden, wenn wirklich darauf zugegriffen wird. Mit dem Konzept des \term{Prefetching} würde man dann alle Text von allen Artikeln laden, weil man davon ausgehen könnte, dass noch weitere Texte angefragt werden würden\footnote{Dies ist das Ergebnis aus \cite{Bernstein99context-basedprefetch}}. \\
Die Frameworks, die im ersten Teil untersucht wurden, zeigen wie flexibel \ORM-Lösungen sein müssen. In Hibernate sind alle Möglichkeiten, die als allgemeine Lösungen für die Kernprobleme verstanden werden, implementiert. Vererbung kann mit allen drei Strategien umgesetzt werden, diese können sogar miteinander gemischt werden. Hibernate hat eine eigene Anfragesprache (HQL) und es ist möglich Abfragen in SQL zu formulieren. Doctrine übernimmt viele Ideen von Hibernate für PHP. TopLink von Oracle konzentriert sich auf ein eigenes \ORM-Tool, welches auch ohne weitere Programmierkentnisse benutzt werden kann um objektorientierte Modelle mit relationalen Schemata zu verbinden. Hibernate und TopLink erscheinen auf den ersten Blick sehr komplex, sind aber sehr gut durchdacht und lassen sich hervorragend konfigurieren und an alle Bedürfnisse anpassen.\\
\\
Die Frage, ob es die perfekte Lösung für den \IMfull gibt, kann man meiner Ansicht nach verneinen. Sei es ein \OODBMS für einen Nischenmarkt oder Hibernate für eine Java-Umgebung oder Doctrine für ein PHP Webprojekt. \ORM-Lösungen müssen so vielen unterschiedlichen Anforderungen gerecht werden und so viele Tradeoffs zwischen Abstraktion und Performanz lösen, dass immer Schwerpunkte von der einen oder anderen Lösung besser zu einem speziellen Projekt passen. Auf lange Sicht würde ich sagen, dass die meisten Entwickler das flexibelste System von allen wählen werden. So ist es aus meiner Sicht schon mit Hibernate. Hibernate ermöglicht für jedes Kernproblem des \IM, die beste Strategie zu wählen und zu konfigurieren, so dass man immer die für seinen speziellen Problemfall beste Lösung aussuchen kann. Nicht ohne Grund gibt es NHibernate für .NET und Doctrine für PHP, die dieselben Ideen wie Hibernate benutzen. \\
\\
Die Entwicklung von \PSCORM war hauptsächlich dadurch motiviert, dass es noch kein speziell angepasstes Framework für PHP gab. Es gibt genug gute \ORM-Lösungen für PHP. So halte ich z.~B. Doctrine für ein sehr gutes \ORM-Framework, welches ich jederzeit in einem neuen Projekt einsetzen würde. Doctrine basiert aber größtenteils auf Konzepten von Hibernate, das wiederum für Java geschrieben wurde. Natürlich funktionieren diese Konzepte auch für andere objektorientierte Programmiersprachen, aber durch die Evaluation und die Vorüberlegungen in den Kapiteln über die Konzepte von \PSCORM wurde auch gezeigt, dass eine Spezialisierung sowohl Vorteile für die Performanz als auch für das Design der Applikation mit sich bringt. \\
Viele Konzepte konnten für \PSCORM aus schon vorhandenen Frameworks übernommen werden. Dabei konnte bei jedem System vom Konzept des dynamischen Code Gebrauch gemacht werden: Bei den Metadaten für die Konfiguration der Mappings, beim Erstellen der eigenen Abfragesprache, beim Verwalten von Beziehungen und natürlich auch beim \term{Object Loading}. Die Entwicklung für all diese Komponenten dynamischen Code zu erzeugen, ist fast abgeschlossen und könnte ein Thema für eine weitere Arbeit sein. Aufgrund der begrenzten Zeit, die für diese Arbeit vorgesehen war, war es jedoch nicht möglich eine vorzeigbare Version zum Abschluss zu veröffentlichen.\\
\\
Ich hätte gerne noch viel mehr Kernprobleme des \IMfull bearbeitet, als es in einer Arbeit wie dieser möglich war. Da ich mich mit diesem Problem seit über vier Jahren in der täglichen Arbeit beschäftige und es immer wieder unter neuen Gesichtspunkten von der praktischen Seite kennengelernt habe, war ich sehr erstaunt, wieviele neue Aspekte ich durch die theoretische und experimentelle Auseinandersetzung mit dem Problem gewinnen konnte. Es ist sicherlich möglich in weiteren Arbeiten die Konzepte für alle Kernprobleme des \IM zu verfeinern und weiter auszuarbeiten, so wie ich es für das \term{Object Loading} gemacht habe. Ich war überrascht, als ich die Evaluation durchführte und mit meinem einfachen Ansatz bessere Laufzeiten als bereits etablierte Systeme erreichen konnte. Sicherlich ist dies nicht repräsentativ für die gesamte Skalierbarkeit der bestehenden \ORM-Lösungen, aber dennoch zeigt es, dass noch viel Potential zur Optimierung vorhanden ist.\\
Ich hoffe, dass in Zukunft nicht nur die großen Software- und Datenbankfirmen interne Forschungen für ihre eigenen \IM-Lösungen anstellen, sondern viele weitere Arbeiten zum Thema enstehen, die vielleicht auch in einer Suchmaschine mit dem Schlüsselwort \IMfull gefunden werden.
